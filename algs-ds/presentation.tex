\documentclass{beamer}
\usetheme{Rochester}
\mode<presentation>

\input{preamble}

\title{Algorithms and Data Structures}

\author{Darren Foong}

\date{January 2017}

\begin{document}

\begin{frame}
 \titlepage
\end{frame}

\begin{frame}
 \frametitle{Overview}
 \tableofcontents
\end{frame}

\section{Searching}

\begin{frame}
 \frametitle{Git}
  \visible<2->{
   \begin{block}{Problem}
    Find $n$ such that commit $n$ is ``good" and commit $n+1$
    is ``bad", i.e.\ commit $n+1$ introduced the error.
   \end{block}
  }

  \vspace{1cm}

  \visible<1->{
   \begin{center}
   \scalebox{1.2} {
    \begin{tikzpicture}
     \draw (0,0) -- (8,0);

     \foreach \i [evaluate=\i as \x using int(\i+50)]  in {0,...,8} {
      \fill[blue] (\i cm, 0) circle (4pt);
      \node at (\i cm, -12pt) {$\x$};
     }

     \fill[green] (0 cm, 0) circle (4pt);
     \fill[red] (8 cm, 0) circle (4pt);

     \pause
     \pause
     \fill[red](4 cm, 0) circle (4pt);

     \pause
     \draw[decoration={brace,raise=5pt},decorate] (1 cm, 0) -- (3 cm, 0) node[midway,yshift=0.5cm] {possibly bad};
     \draw[decoration={brace,raise=5pt},decorate] (5 cm, 0) -- (7 cm, 0) node[midway,yshift=0.5cm] {definitely bad};

    \end{tikzpicture}
   }
   \end{center}
  }
\end{frame}

\begin{frame}[fragile]
 \frametitle{\texttt{git bisect}}
 \begin{itemize}
  \item Linear search takes $7$ steps in the worst-case $\Rightarrow O(n)$
  \item Binary search takes $\approx \lg_2 7 \approx 3$ steps in the worst-case $\Rightarrow O(\lg n)$
  \item \texttt{git} has in-built binary search:
  \begin{verbatim}
$ git bisect start
$ git bisect good
$ git bisect bad
...
$ b41e... is the first bad commit
  \end{verbatim}
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Binary search trees}
 \begin{itemize}
  \item A binary tree with \emph{ordered keys}
   \begin{itemize}
    \item left child is less than parent
    \item right child is greater than parent
   \end{itemize}
  \item \emph{In-order traversal} returns keys in sorted order
  \item Time complexity for searching, insertion, and deletion is
        proportional to \emph{height} of the tree; $O(\lg n)$ for a
        balanced tree
 \end{itemize}
 \begin{center}
  \scalebox{1.0} {
   \begin{tikzpicture}[every tree node/.style={minimum width=0.5cm,
                                               draw,
                                               circle},
                       edge from parent/.style={draw,
                                                edge from parent path={
                                                 (\tikzparentnode) --
                                                 (\tikzchildnode)}},
                       sibling distance=1.0cm,
                       level distance=1.5cm]
    \Tree [.4 [.2 [.1 ] [.3 ] ] [.6 [.5 ] [.7 ] ] ]
   \end{tikzpicture}
  }
 \end{center}
\end{frame}

\begin{frame}
 \frametitle{Pathological cases}
 \begin{itemize}
  \item A binary search tree can end up unbalanced depending on the
        order of operations
  \item Insert na\"ively $1,2,\ldots,7$ in order:
 \end{itemize}
 \begin{center}
  \scalebox{0.5} {
   \begin{tikzpicture}[every tree node/.style={minimum width=0.5cm,
                                               draw,
                                               circle},
                       edge from parent/.style={draw,
                                                edge from parent path={
                                                 (\tikzparentnode) --
                                                 (\tikzchildnode)}},
                       sibling distance=1.0cm,
                       level distance=1.5cm,
                       blank/.style={color=gray,dashed}]
    \Tree [.1 \edge[blank]{}; \node[blank]{};
              [.2 \edge[blank]{}; \node[blank]{};
                  [.3 \edge[blank]{}; \node[blank]{};
                      [.4 \edge[blank]{}; \node[blank]{};
                          [.5 \edge[blank]{}; \node[blank]{};
                              [.6 \edge[blank]{}; \node[blank]{};
                                  [.7 ] ] ] ] ] ] ]
   \end{tikzpicture}
  }
 \end{center}
\end{frame}

\begin{frame}
 \frametitle{Self-balancing binary search trees}
 \begin{itemize}
  \item Performs rebalancing (``housekeeping") when carrying out
        operations to ensure height of tree is $O(\lg n)$
  \item Examples:
  \begin{itemize}
   \item Red-black trees (Java \texttt{TreeMap}, \texttt{TreeSet},
         C++ \texttt{std::map}, \texttt{std::set})
   \item AVL trees
  \end{itemize}
 \end{itemize}
\end{frame}

\section{Big-O notation}

\begin{frame}
 \frametitle{Big-O notation}
 \begin{itemize}
  \item ``number of steps/amount of time needed as a function of input
        size $n$"
 \end{itemize}
 \begin{center}
 \begin{tabular}{rll}
  constant & $O(1)$ & \texttt{HashMap.get(key)} \\
  logarithmic & $O(\lg n)$ & binary search \\
  linear & $O(n)$ & finding maximum value in an array \\
  log-linear & $O(n \lg n)$ & merge sort \\
  quadratic & $O(n^2)$ & insertion sort \\
  cubic & $O(n^3)$ & matrix multiplication \\
  exponential & $O(2^n)$ & travelling salesman problem \\
 \end{tabular}
 \end{center}
 \begin{itemize}
  \item base of $\lg$, $O$, $o$, $\omega$, $\Omega$, $\Theta$
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Hidden constants}
 \begin{itemize}
  \item Beware of hidden constants
  \item Also, abuse of notation
 \end{itemize}
 \begin{align*}
  n^2 = O(n^2) \\
  1234567890n^2 = O(n^2) \\
  100n^2 + n + 1 = O(n^2) \\
  n^3 + 10000000000000 = O(n^3) \\
  1000000000000n \textnormal{ and } n^2 \textnormal{?} \\
 \end{align*}
\end{frame}

\section{Sorting}

\begin{frame}
 \frametitle{Insertion sort}
 \begin{center}
 \begin{tabular}{rl}
  $\vert$ 4 3 5 6 1 2 & start; sorted on left, unsorted on right \pause \\
  \underline{4} $\vert$ 3 5 6 1 2 & \pause \\
  \underline{3} 4 $\vert$ 5 6 1 2 & \pause \\
  3 4 \underline{5} $\vert$ 6 1 2 & \pause \\
  3 4 5 \underline{6} $\vert$ 1 2 & \pause \\
  \underline{1} 3 4 5 6 $\vert$ 2 & \pause \\
  1 \underline{2} 3 4 5 6 $\vert$ & terminate when right is empty \pause \\
 \end{tabular}
 \end{center}
 \begin{itemize}
  \item Number of iterations: $n$
  \item Number of operations in each iteration: average $n$
  \item Average time complexity: $O(n^2)$
  \item Worst case: $O(n^2)$ if the array is reversed
  \item Best case: $O(n)$ if the array is already sorted
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Merge sort}
 \begin{itemize}
  \item Divide-and-conquer approach
  \item Idea: split array into two, recursive merge sort halves, merge
        sorted halves
 \end{itemize}
 \begin{center}
 \begin{tabular}{cl}
  5 4 2 8 3 1 6 7 & start \pause \\
  5 4 2 8 \hspace{0.5cm}  3 1 6 7 & split \pause \\
  5 4 \hspace{0.5cm} 2 8 \hspace{0.5cm} 3 1 \hspace{0.5cm} 6 7 & split further \pause \\
  4 5 \hspace{0.5cm} 2 8 \hspace{0.5cm} 1 3 \hspace{0.5cm} 6 7 & sort base case (two elements) \pause \\
  2 4 5 8 \hspace{0.5cm} 1 3 6 7 & merge \pause \\
  1 2 3 4 5 6 7 8 & merge again; terminate \pause \\
 \end{tabular}
 \end{center}
 \begin{itemize}
  \item Number of iterations: $2 \lg n = O(\lg n)$
  \item Number of operations in each iteration: $n$
  \item Average/best/worst case: $O(n \lg n)$
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Aside: implementing merge sort}
 \begin{itemize}
  \item What is wrong with this C implementation of merge sort?
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Aside: tail-call optimisation}
 \begin{itemize}
  \item TODO
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Quick sort}
 \begin{itemize}
  \item Divide-and-conquer approach
  \item Idea: pick a \emph{pivot} element, quick sort array of elements
        lesser than pivot, quick sort array of elements greater than
        pivot
 \end{itemize}
 \begin{center}
  \begin{tabular}{cl}
   \underline{5} 4 2 8 3 1 6 7 & start; pick $5$ as pivot \pause \\
   \framebox{2 3 1 4} 5 \framebox{8 6 7} & partition \pause \\
   \framebox{\underline{2} 3 1 4} 5 \framebox{\underline{8} 6 7} & pick $2$ and $8$ as pivots \pause \\
   \framebox{\framebox{1} 2 \framebox{3 4}} 5 \framebox{\framebox{6 7} 8} & partition; sort base case \pause \\
   1 2 3 4 5 6 7 8 & terminate \pause \\
  \end{tabular}
 \end{center}
 \begin{itemize}
  \item Number of iterations: average $\lg n$
  \item Number of operations per iteration: $n$
  \item Average time complexity: $O(n \lg n)$
  \item Worst case: $O(n^2)$ if pivot is the smallest/greatest
  \item Best case: $O(n \lg n)$ if pivot is the median; reduces to merge
        sort
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Sorting in practice}
 \begin{itemize}
  \item Quick sort: need to pick a good pivot, does not guarantee $O(\lg n)$
  \item Merge sort can perform worse than a well-implemented quick sort
  \item In practice: merge sort (and/or) quick sort + insertion sort
  \item Merge sort is also used as a basis for \emph{external sort},
        i.e.\ the amount of data to sort cannot fit into memory
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Java implementation}
 \begin{block}{Arrays.sort() (Java 7 onwards)}
The sorting algorithm is a Dual-Pivot Quicksort by Vladimir
Yaroslavskiy, Jon Bentley, and Joshua Bloch. This algorithm offers
$O(n \lg n)$ performance on many data sets that cause other quicksorts
to degrade to quadratic performance, and is typically faster than
traditional (one-pivot) Quicksort implementations.
 \end{block}
 \begin{block}{Collections.sort()}
The implementation was adapted from Tim Peters's list sort for Python
(TimSort).
 \end{block}
\end{frame}

\begin{frame}[fragile]
 \frametitle{Java implementation}
 \begin{verbatim}
private static final int MAX_RUN_COUNT = 67;
private static final int MAX_RUN_LENGTH = 33;
private static final int QUICKSORT_THRESHOLD = 286;
private static final int INSERTION_SORT_THRESHOLD = 47;
private static final int
  COUNTING_SORT_THRESHOLD_FOR_BYTE = 29;
private static final int
  COUNTING_SORT_THRESHOLD_FOR_SHORT_OR_CHAR = 3200;
 \end{verbatim}
\end{frame}

\section{Maps}

\begin{frame}
 \frametitle{Maps}
 \begin{itemize}
  \item Also known as ``tables" or ``dictionaries" (Python)
  \item Store \emph{key-value pairs}
 \end{itemize}
 \begin{center}
 Map interface \\
 \vspace{0.5cm}
 \begin{tabular}{c|c|c}
  Map & Java & C++ \\
  & \texttt{Map} & \texttt{std::map}/\texttt{std::unordered\_map} \\
  \hline
  put(key) & \texttt{put(key)} & \texttt{insert(key)} \\
  get(key) & \texttt{get(key)} & \texttt{[key]} \\
  delete(key) & \texttt{remove(key)} & \texttt{erase(key)} \\
 \end{tabular}
 \end{center}
 \begin{itemize}
  \item Implementations: binary search trees, hash tables
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Binary search trees}
 \begin{itemize}
  \item Usual implementation: red-black trees (Java \texttt{TreeMap},
        C++ \texttt{std::map})
  \item Each tree node contains key and a pointer to the value
  \item put(key) uses tree's insert method ($O(\lg n)$)
  \item get(key) searches the tree in $O(\lg n)$ time
  \item delete(key) uses tree's delete method ($O(\lg n)$)
  \item Advantages over hash tables: can iterate on keys by order
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Hash tables}
 \begin{itemize}
  \item Java \texttt{HashMap} and C++ \texttt{std::unordered\_map}
  \item Need to calculate \emph{hash} of a key, but possibility of
        collisions
  \item If $h(k)$ maps strings to 32-bit integers, there is a chance
        that $h(k_1) = h(k_2)$
  \item Two approaches of handling collisions: chaining and open
        addressing
  \item Advantages over binary search trees: fast
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Chaining}
   \begin{center}
   \scalebox{0.65} {
    \begin{tikzpicture}
     \foreach \i [evaluate=\i as \j using int(1+\i),
                  evaluate=\i as \x using int(11-\i)] in {1,...,10} {
      \draw (0, \i) rectangle (1, \j) node [midway] {\x};
      \draw (1, \i + 0.5) -- (2, \i + 0.5);
     }

     \newcounter{a}
     \setcounter{a}{0}

     \foreach \i in {0,...,2} {
      \draw (\i + 2, 10) rectangle (\i + 3, 11) node [midway] {$a_{\arabic{a}}$};
      \stepcounter{a}
     }

     \foreach \i in {0,...,3} {
      \draw (\i + 2, 7) rectangle (\i + 3, 8) node [midway] {$a_{\arabic{a}}$};
      \stepcounter{a}
     }

     \foreach \i in {0,...,3} {
      \draw (\i + 2, 4) rectangle (\i + 3, 5) node [midway] {$a_{\arabic{a}}$};
      \stepcounter{a}
     }

     \foreach \i in {0,...,4} {
      \draw (\i + 2, 1) rectangle (\i + 3, 2) node [midway] {$a_{\arabic{a}}$};
      \stepcounter{a}
     }

     \foreach \i in {2,3,5,6,8,9} {
      \filldraw[fill=white, draw=black] (2, \i + 0.5) circle (0.2);
     }

     \draw[decoration={brace},decorate] (-1, 1) -- (-1, 11) node[midway,xshift=-4cm] {buckets i.e.\ outputs of $h(k) \mod M$};

    \end{tikzpicture}
   }
   \end{center}
\end{frame}

\begin{frame}
 \frametitle{Open addressing}
  \begin{columns}[t]
   \begin{column}{0.3\textwidth}
   \begin{center}
   \scalebox{0.7} {
    \begin{tikzpicture}
     \foreach \i [evaluate=\i as \j using int(1+\i),
                  evaluate=\i as \x using int(17-\i)] in {1,...,16} {
      \draw (0, \i) rectangle (1, \j) node [midway,xshift=-1cm] {\x};
     }

     \newcounter{b}
     \setcounter{b}{0}

     \foreach \i in {1,2,6,9,13,14,15} {
      \draw (0, \i) rectangle (1, \i + 1) node [midway] {$a_{\arabic{b}}$};
      \stepcounter{b}
     }

     \filldraw[fill=gray] (0, 8) rectangle (1, 9);

     \draw [<-] (1, 14.5) arc (-90:90:0.5);
     \draw [<-] (1, 13.5) arc (-90:90:0.5);
     \draw [<-] (1, 12.5) arc (-90:90:0.5);
     \draw [<-] (1, 8.5) arc (-90:90:0.5);
    \end{tikzpicture}
   }
   \end{center}
   \end{column}
   \begin{column}{0.7\textwidth}
    \begin{itemize}
     \item Linear probing: insert into $h(k) + j \mod M$
     \item Quadratic probing: insert into $h(k) + cj + dj^2 \mod M$
     \item Double hashing: insert into $h_1(k) + j \cdot h_2(k) \mod M$
     \item Deletion is non-trivial, need a special marker
    \end{itemize}
   \end{column}
  \end{columns}
\end{frame}

\begin{frame}
 \frametitle{Collisions}
 \begin{itemize}
  \item Quality of the hash function is crucial to hash table
        performance
  \item put(), get(), and delete() are $O(1)$ if hash function is good
  \item Extreme example: $h(k) = 1$ reduces chaining hash table to an
        array with $O(n)$ performance
  \item Java: if \texttt{o1.equals(o2)}, \\
        then \texttt{o1.hashCode() == o2.hashCode()}
  \item Java 8: chaining array becomes a binary search tree after
        \texttt{TREEIFY\_THRESHOLD = 8}
  \item Hash tables are initialised with a small capacity; dynamically
        resized upon reaching some threshold (load factor)
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Database indexing}
 \begin{itemize}
  \item A database index is basically a map, but which implementation?
  \item In practice: B-trees (a generalisation of binary search trees),
        providing retrieval in $O(\lg n)$ time
  \item Hash tables do not provide order (important for \texttt{ORDER BY}
        queries)
  \item B-tree nodes are blocks; reduce number of disk seeks
  \item B-trees are in most file systems!
 \end{itemize}
\end{frame}

\section{Priority queues}

\begin{frame}
 \frametitle{Priority queues}
 \begin{itemize}
  \item Like a queue, but each item has a priority
 \end{itemize}
 \begin{center}
 Priority queue interface \\
 \vspace{0.5cm}
 \begin{tabular}{c|c|c}
  Map & Java & C++ \\
  & \texttt{PriorityQueue} & \texttt{std::priority\_queue} \\
  \hline
  put(item) & \texttt{add(item)} & \texttt{push(key)} \\
  min() & \texttt{peek()} & \texttt{top()} \\
  extractMin() & \texttt{poll()} & \texttt{pop()} \\
  decreaseKey(item) & \texttt{remove(item)+} & - \\
  & \texttt{add(item)} & \\
 \end{tabular}
 \end{center}
\end{frame}

\begin{frame}
 \frametitle{Unsorted array}
 \begin{center}
  4 5 7 9 2 1 0 8 3 6
 \end{center}
 \begin{itemize}
  \item put(item): at to end of array, $O(1)$
  \item min(): linear search, $O(n)$
  \item extractMin(): linear search + shift, $O(n)$
  \item decreaseKey(item): decrease, $O(1)$
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Sorted array}
 \begin{center}
  0 1 2 3 4 5 6 7 8 9
 \end{center}
 \begin{itemize}
  \item put(item): binary search + shift, $O(n)$
  \item min(): head of array, $O(1)$
  \item extractMin(): head of array + shift, $O(n)$
  \item decreaseKey(item): decrease + shift, $O(n)$
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Binary search tree}
 \begin{center}
  \scalebox{0.6} {
   \begin{tikzpicture}[every tree node/.style={minimum width=0.5cm,
                                               draw,
                                               circle},
                       edge from parent/.style={draw,
                                                edge from parent path={
                                                 (\tikzparentnode) --
                                                 (\tikzchildnode)}},
                       sibling distance=1.0cm,
                       level distance=1.5cm]
    \Tree [.5 [.2 [.1 [.0 ] ] [.3 [.4 ] ] ] [.7 [.6 ] [.8 [.9 ]] ] ]
   \end{tikzpicture}
  }
 \end{center}
 \begin{itemize}
  \item put(item): tree insert method, $O(\lg n)$
  \item min(): find left-most item, $O(\lg n)$
  \item extractMin(): find left-most item, tree delete method, $O(\lg n)$
  \item decreaseKey(item): tree delete method, tree insert method, $O(\lg n)$
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Binary heap}
 \begin{center}
  \scalebox{0.6} {
   \begin{tikzpicture}[every tree node/.style={minimum width=0.5cm,
                                               draw,
                                               circle},
                       edge from parent/.style={draw,
                                                edge from parent path={
                                                 (\tikzparentnode) --
                                                 (\tikzchildnode)}},
                       sibling distance=1.0cm,
                       level distance=1.5cm]
    \Tree [.0 [.2 [.5 [.9 ] [.7 ] ] [.6 [.8 ] ] ] [.1 [.4 ] [.3 ] ] ]
   \end{tikzpicture}
  }
 \end{center}
 \begin{itemize}
  \item Binary heap: complete binary tree
  \item Heap property: children are always greater than the parent
  \item ``Bubble up": rotate children and parents at each level until
        heap property is satisfied
  \item put(item): add to last, ``bubble up", $O(\lg n)$
  \item min(): root of tree, $O(1)$
  \item extractMin(): replace root with last, ``bubble down", $O(\lg n)$
  \item decreaseKey(item): decrease key, ``bubble up", $O(\lg n)$
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Applications of priority queues}
 \begin{itemize}
  \item Dijkstra's shortest path algorithm
  \item Process scheduling
  \item Other implementations:
  \begin{itemize}
   \item Binomial heap: insert() in $O(1)$
   \item Fibonacci heap: decreaseKey() in $O(1)$
  \end{itemize}
 \end{itemize}
\end{frame}

\section{Interesting algorithms}

\begin{frame}
 \frametitle{Bloom filter}
 \begin{itemize}
  \item Probabilistic data structure
 \end{itemize}
 \begin{center}
 Bloom filter interface \\
 \vspace{0.5cm}
 \begin{tabular}{c}
  Bloom filter \\
  \hline
  put(item) \\
  exists(item) \\
 \end{tabular}
 \end{center}
 \begin{itemize}
  \item If exists(item) is true, then the item \emph{may} be in the set
  \item If exists(item) is false, then the item is definitely not in the
        set
  \item No delete(item)
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Bloom filter}
 \begin{itemize}
  \item Empty Bloom filter: backing array of $M$ bits, all $0$
  \item $k$ different hash functions mapping elements to
        $\{0,1,\cdots,M-1\}$
 \end{itemize}
  \begin{center}
  \scalebox{0.65} {
   \begin{tikzpicture}
    \draw (-3, 1) [draw=none] rectangle (1, 2) node [midway] {$h_1(e_1), h_2(e_1), h_3(e_1)$};

    \foreach \i in {0,...,9} {
     \draw (\i + 2, 1) rectangle (\i + 3, 2);
    }

     \foreach \i in {1,5,9} {
      \draw (\i + 2, 1) rectangle (\i + 3, 2) node [midway] {1};
     }

    \draw (-3, 2.5) [draw=none] rectangle (1, 3.5) node [midway] {$h_1(e_2), h_2(e_2), h_3(e_2)$};

    \foreach \i in {0,...,9} {
     \draw (\i + 2, 2.5) rectangle (\i + 3, 3.5);
    }

     \foreach \i in {2,7,8} {
      \draw (\i + 2, 2.5) rectangle (\i + 3, 3.5) node [midway] {1} ;
     }

    \draw (-3, 4) [draw=none] rectangle (1, 5) node [midway] {$h_1(e_3), h_2(e_3), h_3(e_3)$};

    \foreach \i in {0,...,9} {
     \draw (\i + 2, 4) rectangle (\i + 3, 5);
    }

     \foreach \i in {1,3,8} {
      \draw (\i + 2, 4) rectangle (\i + 3, 5) node [midway] {1};
     }

    \draw (-3, 5.5) [draw=none] rectangle (1, 6.5) node [midway] {Backing array};

    \foreach \i in {0,...,9} {
     \draw (\i + 2, 5.5) [line width=1mm] rectangle (\i + 3, 6.5);
    }

     \foreach \i in {1,2,3,5,7,8,9} {
      \draw (\i + 2, 5.5) [line width=1mm] rectangle (\i + 3, 6.5) node [midway] {1};
     }
   \end{tikzpicture}
  }
  \end{center}
\end{frame}

\begin{frame}
 \frametitle{Bloom filter}
 \begin{itemize}
  \item A normal set implementation uses binary search trees (e.g.\
        \texttt{TreeSet}) or hash tables (e.g.\ \texttt{HashSet})
  \item A Bloom filter uses $O(1)$ space
  \item put(item) is $O(k)$, exists(item) is $O(k)$; can be parallelised
  \item Performance depends on quality of hash functions
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{What's the point?}
 \begin{itemize}
  \item Saves on expensive lookups, at the cost of false positives
  \item Web crawling: ``\emph{have I already indexed this site?}"
   \begin{itemize}
    \item Small chance that you do not crawl an uncrawled site
   \end{itemize}
  \item Recommendation systems: ``\emph{has the user already seen this
        before?}"
   \begin{itemize}
    \item Small chance that you do not recommend something the user has
          not seen before
   \end{itemize}
  \item OkCupid saved 1.2 TB of RAM (a third of previous usage) by using
        Bloom filters for their match recommendation system
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Preliminary: run-length encoding}
 \begin{itemize}
  \item How would you compress \emph{aaaaa} or \emph{yamyam}?
  \item Run-length encoding: store consecutive repeating elements as
        (element, number), e.g.\ \emph{a[5]}, \emph{yam[2]},
        \emph{jeff[200]}
  \item A form of \emph{lossless} compression
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Burrows-Wheeler transform}
 \begin{itemize}
  \item Consider a string ``banana"
  \item Append a terminator ``\$" and list all \emph{rotations}:
 \end{itemize}
 \begin{center}
  \begin{tabular}{l}
   banana\$ \\
   \$banana \\
   a\$banan \\
   na\$bana \\
   ana\$ban \\
   nana\$ba \\
   anana\$b \\
  \end{tabular}
 \end{center}
\end{frame}

\begin{frame}
 \frametitle{Burrows-Wheeler transform}
 \begin{itemize}
  \item Sort table by lexical order (``\$" is ordered last):
 \end{itemize}
 \begin{center}
  \begin{tabular}{l}
   anana\$b \\
   ana\$ban \\
   a\$banan \\
   banana\$ $\leftarrow$ original string \\
   nana\$ba \\
   na\$bana \\
   \$banana \\
  \end{tabular}
 \end{center}
 \begin{itemize}
  \item Store \emph{last column}: ``bnn\$aaa"
  \item Claim: can reconstruct ``banana" from the stored string
  \item (Magically) better for run-length encoding, but why?
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Reconstruction}
 \begin{itemize}
  \item Obtain first column ``aaabnn\$" by sorting last column
        ``bnn\$aaa"
  \item Property: $i$-th occurrence of a character in the first column
        is the $i$-th occurrence of the character in the last column
 \end{itemize}
 \begin{center}
  \begin{tabular}{lll}
   a & \hspace{1.0cm} & b \\
   a & \hspace{1.0cm} & n \\
   a & \hspace{1.0cm} & n \\
   b & \hspace{1.0cm} & \$ $\leftarrow$ original string \\
   n & \hspace{1.0cm} & a \\
   n & \hspace{1.0cm} & a \\
   \$ & \hspace{1.0cm} & a \\
  \end{tabular}
 \end{center}
\end{frame}

\begin{frame}
 \frametitle{Point in polygon}
\end{frame}

\section{Conclusions}

\begin{frame}
 \frametitle{What I did not cover}
 \begin{itemize}
  \item Lists, stacks, queues, sets
  \item Amortised analysis
  \item Graph algorithms
  \item Graphics algorithms
  \item and a lot more
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{References}
 \begin{itemize}
  \item \emph{Introduction to Algorithms} by Cormen, Leiserson, Rivest, and Stein (CLRS)
  \item Cambridge Computer Laboratory courses: \url{https://www.cl.cam.ac.uk/teaching/current/}
  \item \url{https://github.com/darrenfoong/sqc-talks/}
 \end{itemize}
\end{frame}

\end{document}
